{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.av2 = nn.AvgPool2d(kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.av3 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.av4 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.av5 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.un6 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "\n",
    "       \n",
    "        self.un7 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv7 = nn.Conv2d(256 * 2, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.un8 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv8 = nn.Conv2d(128 * 2, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.un9 = nn.UpsamplingNearest2d(scale_factor=4)\n",
    "        self.conv9 = nn.Conv2d(64 * 2, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(32 * 2, 3, kernel_size=5, stride=1, padding=2)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x2 = F.relu(self.bn2(self.conv2(self.av2(x1))), inplace=True)\n",
    "        x3 = F.relu(self.bn3(self.conv3(self.av3(x2))), inplace=True)\n",
    "        x4 = F.relu(self.bn4(self.conv4(self.av4(x3))), inplace=True)\n",
    "        x = F.relu(self.bn5(self.conv5(self.av5(x4))), inplace=True)\n",
    "        x = F.relu(self.bn6(self.conv6(self.un6(x))), inplace=True)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = F.relu(self.bn7(self.conv7(self.un7(x))), inplace=True)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = F.relu(self.bn8(self.conv8(self.un8(x))), inplace=True)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = F.relu(self.bn9(self.conv9(self.un9(x))), inplace=True)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.tanh(self.conv10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.in1 = nn.InstanceNorm2d(16)\n",
    "\n",
    "        self.av2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2_1 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.in2_1 = nn.InstanceNorm2d(32)\n",
    "        self.conv2_2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.in2_2 = nn.InstanceNorm2d(32)\n",
    "\n",
    "        self.av3 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv3_1 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.in3_1 = nn.InstanceNorm2d(64)\n",
    "        self.conv3_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.in3_2 = nn.InstanceNorm2d(64)\n",
    "\n",
    "        self.av4 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv4_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.in4_1 = nn.InstanceNorm2d(128)\n",
    "        self.conv4_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.in4_2 = nn.InstanceNorm2d(128)\n",
    "\n",
    "        self.av5 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv5_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.in5_1 = nn.InstanceNorm2d(256)\n",
    "        self.conv5_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.in5_2 = nn.InstanceNorm2d(256)\n",
    "\n",
    "        self.av6 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.in6 = nn.InstanceNorm2d(512)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(512, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):      \n",
    "        x = F.leaky_relu(self.in1(self.conv1(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in2_1(self.conv2_1(self.av2(x))), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in2_2(self.conv2_2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in3_1(self.conv3_1(self.av3(x))), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in3_2(self.conv3_2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in4_1(self.conv4_1(self.av4(x))), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in4_2(self.conv4_2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in5_1(self.conv5_1(self.av5(x))), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in5_2(self.conv5_2(x)), 0.2, inplace=True)\n",
    "        x = F.leaky_relu(self.in6(self.conv6(self.av6(x))), 0.2, inplace=True)\n",
    "        x = self.conv7(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator_output torch.Size([2, 3, 128, 128])\n",
      "Discriminator_output torch.Size([2, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "g, r = Generator(), Discriminator()\n",
    "test_imgs = torch.randn([2,3,128,128])\n",
    "test_imgs = g(test_imgs)\n",
    "test_res =  r(test_imgs)\n",
    "\n",
    "print(\"Generator_output\", test_imgs.size())\n",
    "print(\"Discriminator_output\", test_res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugment():\n",
    "    def __init__(self, resize):\n",
    "        self.data_tramsform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(resize, scale=(0.9, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip()\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.data_tramsform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonoColorDataset(data.Dataset):\n",
    "    def __init__(self, file_list, transform_tensor, augment=None):\n",
    "        self.file_list = file_list\n",
    "        self.augment = augment\n",
    "        self.transform_tensor = transform_tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert(\"RGB\")\n",
    "        \n",
    "        if self.augment is not None:\n",
    "            img = self.augment(img)\n",
    "        \n",
    "        img_gray = img.copy()\n",
    "        img_gray = transform_tensor.functional.to_grayscale(img_gray, num_output_channels=3)\n",
    "        \n",
    "        img = self.transform_tensor(img)\n",
    "        img_gray = self.transform_tensor(img_gray)\n",
    "        \n",
    "        return img, img_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataloade(file_path, batch_size):\n",
    "    size = 128\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    train_dataset = MonoColorDataset(file_path_train, transform=ImgTransform(size, mean, std), augment=DataAugment(size))\n",
    "    train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_grid_imgs(imgs, nrow, save_path=None):\n",
    "    imgs = torchvision.utils.make_grid(\n",
    "        imgs[0:(nrow**2), :, :, :], nrow=nrow, padding=5)\n",
    "    imgs = imgs.numpy().transpose([1,2,0])\n",
    "    imgs -= np.min(imgs)\n",
    "    imgs /= np.max(imgs)\n",
    "    \n",
    "    plt.imshow(imgs)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show([])\n",
    "    \n",
    "    if save_path is not None:\n",
    "        io.imsave(save_path, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(file_path_test, model_G, device=\"cuda:0\", nrow=4):\n",
    "    model_G = model_G.to(device)\n",
    "    size = 128\n",
    "    mean = (0.5, 0.5, 0.5)\n",
    "    std = (0.5, 0.5, 0.5)\n",
    "    test_dataset = MonoColorDataset(\n",
    "        file_path_test,\n",
    "        transform=ImgTransform(size, mean, std),\n",
    "        augment = None\n",
    "    )\n",
    "    test_dataloader = data.DataLoader(test_dataset, batch_size=nrow**2, shuffle=False)\n",
    "    \n",
    "    for img, img_gray in test_dataloader:\n",
    "        mat_grid_imgs(img_gray, nrow=nrow)\n",
    "        img = img.to(device)\n",
    "        img_gray = img_gray.to(device)\n",
    "        img_fake = model_G(img_gray)\n",
    "        img_fake = img_fake.to(\"cpu\")\n",
    "        img_fake = img_fake.datach()\n",
    "        mat_grid_imgs(img_fake, nrow=nrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color, transform\n",
    "\n",
    "def color_mono(image, threshold=150):\n",
    "    image_size = image.shape[0] * image.shape[1]\n",
    "    \n",
    "    diff = np.abs(np.sum(image[:,:,0] - image[:,:,1])) / image_size\n",
    "    diff += np. abs(np.sum(image[:,:,0] - image[:,:,2])) / image_size\n",
    "    diff += np.abs(np.sum(image[:,:,1] - image[:,:,2])) / image_size\n",
    "    \n",
    "    if diff > threshold:\n",
    "        return \"color\"\n",
    "    else:\n",
    "        return \"mono\"\n",
    "\n",
    "    def bright_check(image, ave_thres=0.15, std_thres=0.1):\n",
    "        try:\n",
    "            image = color.rgb2gray(image)\n",
    "            \n",
    "            if image.shape[0] < 144:\n",
    "                return False\n",
    "            if np.average(image) > (1.-ave_thres):\n",
    "                return False\n",
    "            if np.average(image) < ave_thres:\n",
    "                return False\n",
    "            if np.std(image) < std_thres:\n",
    "                return False\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    paths = glob.glob(\"./test2018/*\")\n",
    "    \n",
    "    for i, path in enumerate(paths):\n",
    "        image = io.imread(path)\n",
    "        save_name = \"./trans\\\\mscoco_\" + str(i) + \".png\"\n",
    "        x = image.shape[0]\n",
    "        y = image.shape[1]\n",
    "        \n",
    "        try:\n",
    "            clip_half = min(x,y)/2\n",
    "            image = image[int(x/2 - clip_half): int(x/2 + clip_half), int(y/2 - clip_half): int(y/2 + clip_half), :]\n",
    "            \n",
    "            if color_mono(image) == \"color\":\n",
    "                if bright_check(image):\n",
    "                    image = transform.resize(image, (144, 144, 3), anti_aliasing=True)\n",
    "                    image = np.uint8(image*255)\n",
    "                    io.imsave(save_name, image)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_G, model_D, epoch, epoch_plus):\n",
    "    device = \"cude:0\"\n",
    "    batch_size = 32\n",
    "    \n",
    "    model_G = model_G.to(device)\n",
    "    model_D = model_D.to(device)\n",
    "    \n",
    "    params_G = torch.optim.Adam(model_G,parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    params_D = torch.optim.Adam(model_D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    true_labels = torch.ones(batch_size, 1,4,4).to(device)\n",
    "    false_labels = torch.zeros(batch_size, 1,4,4).to(device)\n",
    "    \n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    mae_loss = nn.L1Loss()\n",
    "    \n",
    "    log_loss_G_sum, log_loss_G_bce, log_loss_G_mae = list(), list(), list()\n",
    "    log_loss_D = list()\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_G_sum, loss_G_bce, loss_G_mae = list(), list(), list()\n",
    "        loss_D = list()\n",
    "        \n",
    "        train_dataloader = load_train_dataloade(file_path_train, batch_size)\n",
    "        \n",
    "        for real_color, input_gray in train_dataloader:\n",
    "            batch_len = len(real_color)\n",
    "            real_color = real_color.to(device)\n",
    "            inpiut_gray = input_gray.to(device)\n",
    "            fake_color = model_G(input_gray)\n",
    "            fake_color_tensor = fake_color.detach()\n",
    "            LAMBD = 100.0\n",
    "            out = model_D(fake_color)\n",
    "            loss_G_bce_tmp = bce_loss(out)\n",
    "            loss_G_mae_tmp = LAMBD * mae_loss(fake_color, real_color)\n",
    "            loss_G_sum_tmp = loss_G_bce_tmp + loss_G_mae_tmp\n",
    "            \n",
    "            loss_G_bce.append(loss_G_bce_tmp.item())\n",
    "            loss_G_mae.append(loss_G_mae_tmp.item())\n",
    "            loss_G_sum.append(loss_G_sum_tmp.item())\n",
    "            \n",
    "            params_D.zero_grad()\n",
    "            params_G.zero_grad()\n",
    "            loss_G_sum_tmp.backward()\n",
    "            params_G.step()\n",
    "            \n",
    "            real_out = model_D(real_color)\n",
    "            fake_out = model_D(fake_color_tensor)\n",
    "            \n",
    "            loss_D_real = bce_loss(real_out, true_labels[:batch_len])\n",
    "            loss_D_fake = bce_loss(fake_out, false_labels[:batch_len])\n",
    "            \n",
    "            loss_D_tmp = loss_D_real + loss_D_fake\n",
    "            loss_D.append(loss_D_tmp.item())\n",
    "            \n",
    "            params_D.zero_grad()\n",
    "            params_G.zero_grad()\n",
    "            loss_D_tmp.backward()\n",
    "            params_D.backward()\n",
    "            params_D.step()\n",
    "\n",
    "    i = i + epoch_plus\n",
    "    print(i, \"loss_G\", np.mean(loss_G_sum), \"loss_D\", np.mean(loss_D))\n",
    "    log_loss_G_sum.append(np.mean(loss_G_sum))\n",
    "    log_loss_G_bce.append(np.mean(loss_G_bce))\n",
    "    log_loss_G_mae.append(np.mean(loss_G_mae))\n",
    "    log_loss_D.append(np.mean(loss_D))\n",
    "    file_path_test = glob.glob(\"test/*\")\n",
    "    evaluate_test(file_path_test, model_G, device)\n",
    "    return model_G, model_D, [log_loss_G_sum, log_loss_G_bce, log_loss_G_mae, log_loss_D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
